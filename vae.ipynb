{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varational Autoencoders in ZhuSuan\n",
    "\n",
    "### This code implements a VAE with Gaussian prior and Bernoulli likelihood based on ZhuSuan.\n",
    "#### The framework has been setup, please only fill the space with \"TODO\" comments.\n",
    "#### You may see some detailed instructions in the comments. For detailed usage of ZhuSuan, please see the documentation on http://zhusuan.readthedocs.io/en/latest/concepts.html\n",
    "\n",
    "#### If you have any questions, please contact with me: lucheng.lc15@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import zhusuan as zs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, img_as_ubyte\n",
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Load MNIST Dataset\n",
    "We use tensorflow tools to load dataset for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, label_train), _ = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train.shape, label_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Some Utils for Training and Visualization\n",
    "\n",
    "Here are some functions for next steps. You don't need to know the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterbatches(arrays, *, num_batches=None, batch_size=None, shuffle=True, include_final_partial_batch=True):\n",
    "    assert (num_batches is None) != (batch_size is None), 'Provide num_batches or batch_size, but not both'\n",
    "    n = arrays[0].shape[0]\n",
    "    assert all(a.shape[0] == n for a in arrays[1:])\n",
    "    inds = np.arange(n)\n",
    "    if shuffle: np.random.shuffle(inds)\n",
    "    sections = np.arange(0, n, batch_size)[1:] if num_batches is None else num_batches\n",
    "    for batch_inds in np.array_split(inds, sections):\n",
    "        if include_final_partial_batch or len(batch_inds) == batch_size:\n",
    "            yield tuple(a[batch_inds] for a in arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_collections(x, filename, shape=(10, 10), scale_each=False,\n",
    "                           transpose=False):\n",
    "    \"\"\"\n",
    "    :param shape: tuple\n",
    "        The shape of final big images.\n",
    "    :param x: numpy array\n",
    "        Input image collections. (number_of_images, rows, columns, channels) or\n",
    "        (number_of_images, channels, rows, columns)\n",
    "    :param scale_each: bool\n",
    "        If true, rescale intensity for each image.\n",
    "    :param transpose: bool\n",
    "        If true, transpose x to (number_of_images, rows, columns, channels),\n",
    "        i.e., put channels behind.\n",
    "    :return: `uint8` numpy array\n",
    "        The output image.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    if transpose:\n",
    "        x = x.transpose(0, 2, 3, 1)\n",
    "    if scale_each is True:\n",
    "        for i in range(n):\n",
    "            x[i] = rescale_intensity(x[i], out_range=(0, 1))\n",
    "    n_channels = x.shape[3]\n",
    "    x = img_as_ubyte(x)\n",
    "    r, c = shape\n",
    "    if r * c < n:\n",
    "        print('Shape too small to contain all images')\n",
    "    h, w = x.shape[1:3]\n",
    "    ret = np.zeros((h * r, w * c, n_channels), dtype='uint8')\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if i * c + j < n:\n",
    "                ret[i * h:(i + 1) * h, j * w:(j + 1) * w, :] = x[i * c + j]\n",
    "    ret = ret.squeeze()\n",
    "    io.imsave(filename, ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Build the Generative Model by ZhuSuan\n",
    "\n",
    "Define the generative model according to the generative process.\n",
    "\n",
    "* TODO: complete the network.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@zs.meta_bayesian_net(scope=\"gen\", reuse_variables=True)\n",
    "def build_gen(x_dim, z_dim, n, n_particles=1):\n",
    "    bn = zs.BayesianNet()\n",
    "    z_mean = tf.zeros([n, z_dim])\n",
    "    z = bn.normal(\"z\", z_mean, std=1., group_ndims=1, n_samples=n_particles)\n",
    "    h = tf.layers.dense(z, 500, activation=tf.nn.relu)\n",
    "    ''' \n",
    "        TODO: add one more mlp layer of 500 hidden units with h as the input and return h\n",
    "    '''\n",
    "    x_logits = tf.layers.dense(h, x_dim)\n",
    "    bn.deterministic(\"x_mean\", tf.sigmoid(x_logits))\n",
    "    bn.bernoulli(\"x\", x_logits, group_ndims=1)\n",
    "    return bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the variational posterior model.\n",
    "- TODO: complete the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@zs.reuse_variables(scope=\"q_net\")\n",
    "def build_q_net(x, z_dim, n_z_per_x):\n",
    "    '''\n",
    "        TODO: define a Bayesian network\n",
    "        HINT: see the generative model\n",
    "    '''\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    '''\n",
    "        TODO: add two more mlp layers of 500 hidden units\n",
    "        HINT: from x to h\n",
    "    '''\n",
    "    z_mean = tf.layers.dense(h, z_dim)\n",
    "    z_logstd = tf.layers.dense(h, z_dim)\n",
    "    '''\n",
    "        TODO: define q(z|x) using the Gaussian distribution of ZhuSuan\n",
    "            > given input\n",
    "                - \"z\", z_mean, z_logstd (note that it is not std), n_z_per_x\n",
    "                - set group_ndims as 1\n",
    "            > e.g.\n",
    "                - z = bn.normal(\"z\", ..., logstd=..., group_ndims=..., n_samples=...)\n",
    "    '''\n",
    "    return bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Set the Hyperparameters\n",
    "\n",
    "The following hyperparameters work well. However, you can modify them anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 28 * 28\n",
    "z_dim = 40\n",
    "n_particles = 1\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs = 3000\n",
    "batch_size = 128\n",
    "save_freq = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Build the Model and the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = tf.placeholder(tf.float32, shape=[None, x_dim], name=\"x\")\n",
    "# Change x to binary form.\n",
    "x = tf.cast(tf.less(tf.random_uniform(tf.shape(x_input)), x_input), tf.int32)\n",
    "n = tf.placeholder(tf.int32, shape=[], name=\"n\")\n",
    "\n",
    "model = build_gen(x_dim, z_dim, n, n_particles)\n",
    "variational = build_q_net(x, z_dim, n_particles)\n",
    "\n",
    "# Define the ELBO and optimize it by SGVB.\n",
    "lower_bound = zs.variational.elbo(model, {\"x\": x}, variational=variational, axis=0)\n",
    "cost = tf.reduce_mean(lower_bound.sgvb())\n",
    "lower_bound = tf.reduce_mean(lower_bound)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "infer_op = optimizer.minimize(cost)\n",
    "\n",
    "x_gen = tf.reshape(model.observe()[\"x_mean\"], [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Train the Model and Save the Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All generated samples are saved to this path.\n",
    "result_path = 'images'\n",
    "if not os.path.exists(result_path):\n",
    "    os.mkdir(result_path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        time_epoch = -time.time()\n",
    "        lbs = []\n",
    "        for i_step, (x_batch, _) in enumerate(iterbatches(\n",
    "            [data_train, label_train], batch_size=batch_size, include_final_partial_batch=False,\n",
    "        )):\n",
    "            x_batch = x_batch.reshape([-1, 28*28])\n",
    "            _, lb = sess.run([infer_op, lower_bound],\n",
    "                             feed_dict={x_input: x_batch,\n",
    "                                        n: batch_size})\n",
    "            lbs.append(lb)\n",
    "        time_epoch += time.time()\n",
    "        print(\"Epoch {} ({:.1f}s): Lower bound = {}\".format(\n",
    "            epoch, time_epoch, np.mean(lbs)))\n",
    "\n",
    "        if epoch % save_freq == 0 or epoch == 1:\n",
    "            images = sess.run(x_gen, feed_dict={n: 100})\n",
    "            name = os.path.join(result_path,\n",
    "                                \"vae_epoch_{}.png\".format(epoch))\n",
    "            save_image_collections(images, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
